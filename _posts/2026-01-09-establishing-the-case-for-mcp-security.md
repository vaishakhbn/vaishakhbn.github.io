---
layout: post
title: "Establishing the Case for MCP Security"
nav: blog
canonical_url: https://medium.com/@vbnarasi/establishing-the-case-for-mcp-security-bc0815eb2e16
---

<p><em>Originally published on Medium: <a href="https://medium.com/@vbnarasi/establishing-the-case-for-mcp-security-bc0815eb2e16">Establishing the Case for MCP Security</a></em></p>

<p><em>Part 1 of 3 in the series “Securing the Future of AI Agents: AuthN &amp; AuthZ in the Model Context Protocol”</em></p><h3>The Rise of Autonomous AI Agents</h3><p>It’s 2026. Today’s AI agents are writing code, querying databases, calling APIs, and increasingly, making decisions that affect production systems. Claude can now edit your files, run your terminal commands, and interact with any tool you expose through MCP. Products like resolve.ai are able to debug your production systems.</p><p>All these agents need a standardized way to interact with external tools and systems. Enter the Model Context Protocol.</p><h3>What is MCP?</h3><p>The Model Context Protocol, developed by Anthropic, is becoming the de facto standard for how AI models interact with external tools and data sources. Think of it as a universal interface that lets any compatible AI model talk to any compatible tool.</p><p>At its core, MCP is elegantly simple:</p><ul><li><strong>MCP Servers</strong> expose tools and resources (databases, APIs, file systems)</li><li><strong>MCP Clients</strong> (AI models) discover and invoke these tools</li><li><strong>The Protocol</strong> standardizes how they communicate</li></ul><p>Here’s what an MCP tool definition looks like:</p><pre>{<br>  &quot;name&quot;: &quot;deploy_to_production&quot;,<br>  &quot;description&quot;: &quot;Deploy code to production environment&quot;,<br>  &quot;inputSchema&quot;: {<br>    &quot;type&quot;: &quot;object&quot;,<br>    &quot;properties&quot;: {<br>      &quot;service&quot;: {&quot;type&quot;: &quot;string&quot;},<br>      &quot;version&quot;: {&quot;type&quot;: &quot;string&quot;}<br>    }<br>  }<br>}</pre><p>MCP’s standardization is very powerful. Instead of building custom integrations for every AI model and every tool, developers can now:</p><ol><li><strong>Build once, use everywhere</strong>: An MCP server works with Claude, GPT-5.2, or any MCP-compatible client</li><li><strong>Discover dynamically</strong>: AI agents can find and use tools they’ve never seen before</li><li><strong>Compose complex workflows</strong>: Chain multiple tools together for sophisticated automation</li></ol><p>Major platforms and enterprises are already adopting MCP in a big way. The ecosystem is exploding, which brings us to the problem.</p><h3>The Security Blind Spot</h3><p>In my opinion, MCP was designed for a trusted world. The specification assumes that if an AI agent can see a tool, it should be able to use it. It treats security as an implementation detail, stating that servers should “implement appropriate access controls”. But, what does “appropriate” mean when your AI agent is autonomous?</p><h3>A Real-World Scenario</h3><p>Imagine a typical enterprise setup:</p><ol><li><strong>DevOps Team</strong> exposes deployment tools via MCP for their AI assistant</li><li><strong>Data Team</strong> exposes production database access for their analytics agent</li><li><strong>HR Team</strong> exposes employee record access for their HR bot</li><li><strong>Customer Support</strong> exposes CRM tools for their service agent</li></ol><p>Without proper authentication and authorization:</p><ul><li>The customer support agent could theoretically access production databases</li><li>The analytics agent could modify employee records</li><li>Any agent could deploy code to production</li></ul><p>One might think, “we’d never expose all these tools to the same agent”. That’s where tool poisoning comes in.</p><h3>The Tool Poisoning Attack Vector</h3><p>Recent research from Invariant Labs exposed a critical vulnerability: tool poisoning attacks[<a href="https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks">https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks</a>]. Here’s how it works:</p><ol><li>An attacker crafts a malicious MCP tool definition</li><li>The tool masquerades as something benign (e.g., “format_document”)</li><li>But its actual implementation exfiltrates data or executes harmful commands</li><li>An unsuspecting AI agent uses the tool, thinking it’s safe</li></ol><p>The attack is particularly bad because:</p><ul><li>AI agents can’t verify what a tool actually does</li><li>Tool descriptions are often vague or misleading</li><li>There’s no cryptographic verification of tool identity</li></ul><p>Without authentication and authorization, any MCP server on your network becomes a potential attack vector.</p><h3>This Isn’t Just an MCP Problem</h3><p>MCP isn’t alone in this security blindness. The Agent-to-Agent (A2A) Protocol, another emerging standard that enables AI agents to communicate with each other, suffers from nearly identical vulnerabilities. In A2A, “Agent Cards” serve the same purpose as MCP tool definitions, and they’re equally vulnerable to poisoning attacks. Palo Alto Networks’ research shows that malicious directives embedded in Agent Cards can instruct agents to “ignore prior instructions” and execute unauthorized commands.</p><p>The pattern is consistent across agent protocols:</p><ul><li><strong>Missing authorization framework</strong>: Neither of the protocols define how to determine what an agent should access</li><li><strong>Metadata poisoning</strong>: MCP tool definitions and A2A Agent Cards are both trusted blindly</li><li><strong>Pull-based discovery</strong>: Agents fetch capabilities without verification in both protocols</li></ul><p>We are facing a widespread agent security crisis. Every protocol being developed for AI agent interaction is making the same assumptions about trust and security. Enterprises are moving fast to integrate AI agents into their workflows. But enterprise environments have strict requirements:</p><ul><li>Compliance (SOC2, HIPAA, GDPR, PCI)</li><li>Audit trails for every action</li><li>Role-based access control</li><li>Zero-trust architecture</li></ul><p>MCP’s current security model doesn’t address these comprehensively.</p><h3>The Authentication/Authorization Gap</h3><p>The draft of the MCP specification introduced an authentication framework based on OAuth 2.1. It looks great in theory:</p><ul><li>Dynamic client registration</li><li>Authorization code flows</li><li>Token exchange</li><li>Resource metadata</li></ul><p>But as we’ll explore in Part 2, this approach is fundamentally misaligned with enterprise reality. OAuth was designed for users clicking “Allow” buttons, not for autonomous agents.</p><h3>Why is this important?</h3><p>The consequences of getting this wrong extend beyond individual organizations:</p><ul><li><strong>Security Breaches</strong>: Unauthorized access to sensitive systems and data</li><li><strong>Compliance Violations</strong>: Failure to maintain proper audit trails and access controls</li></ul><h3>The Path Forward</h3><p>In this series I will chart a practical path to securing MCP for enterprise use cases using existing technologies:</p><ul><li><a href="/blog/why-mcp-authorization-is-a-non-starter-for-enterprise/"><strong>Part 2</strong></a> will dissect why the current OAuth-based approach fails enterprise requirements</li><li><a href="/blog/building-identity-first-authorization-for-mcp/"><strong>Part 3</strong></a> will present an identity-first authorization architecture using modern tools like SPIFFE, OPA, and secure gateways</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=bc0815eb2e16" width="1" height="1" alt="">
